[["index.html", "Creating the flowkernel R package 1 Preliminaries 1.1 DESCRIPTION file 1.2 Package-level documentation", " Creating the flowkernel R package Jacob Bien 2023-03-06 1 Preliminaries This document uses litr to define the flowkernel R package. When the index.Rmd file is rendered, the R package is created along with the bookdown you are reading. To do so in RStudio, you can simply open index.Rmd and press “Knit” to render the bookdown (and open _book/index.html to see the result). More generally, in a console you can run the following: litr::render(&quot;index.Rmd&quot;) 1.1 DESCRIPTION file We start by specifying some basic information for the description file: usethis::create_package( path = &quot;.&quot;, fields = list( Package = params$package_name, Version = &quot;0.0.0.9000&quot;, Title = &quot;Smoothly Varying Mixture of Gaussians Modeling&quot;, Description = &quot;This package uses kernel-smoothed EM to estimate a smoothly varying mixture of Gaussians model.&quot;, `Authors@R` = person( given = &quot;Jacob&quot;, family = &quot;Bien&quot;, email = &quot;jbien@usc.edu&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;) ) ) ) usethis::use_mit_license(copyright_holder = &quot;F. Last&quot;) 1.2 Package-level documentation Let’s include some package-level documentation. Besides being user-friendly, it’s also needed because we’ll be using “import from” later. #&#39; Smoothly Varying Mixture of Gaussians Modeling #&#39; #&#39; This package uses kernel-smoothed EM to estimate a smoothly varying mixture of Gaussians model. #&#39; #&#39; @docType package "],["the-model.html", "2 The model 2.1 Generating data from model 2.2 Visualizing data in one-dimensional case 2.3 Visualizing data and model in one-dimensional case", " 2 The model Our interest is in modeling a sequence of scatterplots measured over time. That is, we observe \\(Y_{it}\\in\\mathbb R^d\\) for \\(i=1,\\ldots,n_t\\) and \\(t=1,\\ldots,T\\). In continuous-time flow cytometry data, we notice that this data has two properties: Each scatterplot looks approximately like a mixture of Gaussians. The general clustering structure seen in each scatterplot is slowly varying over time. To model data like this, we wish to fit a smoothly-varying mixture of Gaussians model: \\[ Y_{it}|\\{Z_{it}=k\\}\\sim N_d(\\mu_{kt},\\Sigma_{kt})\\qquad\\mathbb P(Z_{ik}=k)=\\pi_{kt} \\] where \\((\\mu_{kt},\\Sigma_{kt},\\pi_{kt})\\) are slowly varying parameters. It will be useful to have data generated from this model for testing purposes, so we begin by defining a function for simulating from this model. 2.1 Generating data from model #&#39; Generate data from smoothly-varying mixture of Gaussians model #&#39; #&#39; The smoothly-varying mixture of Gaussians model is defined as follows: #&#39; #&#39; At time t there are n_t points generated as follows: #&#39; #&#39; Y_{it}|\\{Z_{it}=k\\} ~ N_d(mu_{kt},Sigma_{kt}) #&#39; where #&#39; P(Z_{ik}=k)=pi_{kt} #&#39; and the parameters (mu_t, Sigma_t, pi_t) are all slowly varying in time. #&#39; #&#39; This function generates Y and Z. #&#39; #&#39; @param mu_function a function that maps a vector of times to a T-by-K-by-d #&#39; array of means #&#39; @param Sigma_function a function that maps a vector of times to a #&#39; T-K-by-d-by-d array of covariance matrices #&#39; @param pi_function a function that maps a vector of times to a T-by-K vector #&#39; of probabilities #&#39; @param num_points a T vector of integers giving the number of points n_t to #&#39; generate at each time point t. #&#39; @export generate_smooth_gauss_mix &lt;- function(mu_function, Sigma_function, pi_function, num_points) { times &lt;- seq_along(num_points) mu &lt;- mu_function(times) Sigma &lt;- Sigma_function(times) pi &lt;- pi_function(times) K &lt;- ncol(pi) # number of components d &lt;- dim(mu)[3] dimnames(mu) &lt;- list(NULL, paste0(&quot;cluster&quot;, 1:K), NULL) z &lt;- list() # z[[t]][i] = class of point i at time t y &lt;- list() # y[[t]][i,] = d-vector of point i at time t for (t in times) { z[[t]] &lt;- apply(stats::rmultinom(num_points[t], 1, pi[t, ]) == 1, 2, which) y[[t]] &lt;- matrix(NA, num_points[t], d) for (k in 1:K) { ii &lt;- z[[t]] == k # index of points in component k at time t if (sum(ii) == 0) next if (d == 1) y[[t]][ii, ] &lt;- stats::rnorm(n = sum(ii), mean = mu[t, k, ], sd = Sigma[t, k, , ]) else y[[t]][ii, ] &lt;- mvtnorm::rmvnorm(n = sum(ii), mean = mu[t, k, ], sigma = Sigma[t, k, , ]) } } list(y = y, z = z, mu = mu, Sigma = Sigma, pi = pi) } We have used two packages in this function, so let’s add these into our package. usethis::use_package(&quot;stats&quot;) usethis::use_package(&quot;mvtnorm&quot;) ## ✔ Adding &#39;stats&#39; to Imports field in DESCRIPTION ## • Refer to functions with `stats::fun()` ## ✔ Adding &#39;mvtnorm&#39; to Imports field in DESCRIPTION ## • Refer to functions with `mvtnorm::fun()` Let’s generate an example in the \\(d=1\\) case: set.seed(123) d &lt;- 1; K &lt;- 2; ntimes &lt;- 200 ex1 &lt;- list( mu_function = function(times) { mu &lt;- array(NA, c(ntimes, K, d)) mu[, , 1] &lt;- cbind(sin(2 * pi * times / 30), 2) mu }, Sigma_function = function(times) { Sigma &lt;- array(NA, c(ntimes, K, 1, 1)) Sigma[, , 1, 1] &lt;- 0.25 Sigma }, pi_function = function(times) { pi1 &lt;- seq(0.2, 0.8, length=length(times)) cbind(pi1, 1 - pi1) }, num_points = rep(40, ntimes) ) ex1$dat &lt;- generate_smooth_gauss_mix(ex1$mu_function, ex1$Sigma_function, ex1$pi_function, ex1$num_points) 2.2 Visualizing data in one-dimensional case Let’s make a function for visualizing the data in the one-dimensional case. library(magrittr) # we&#39;ll be using the pipe in this document The function will take as input the following argument: ###&quot;y-param&quot;### #&#39; @param y length T list with `y[[t]]` being a n_t-by-d matrix We define this bit of documentation in its own code chunk so that it can be easily reused since multiple functions in the package take it as input. #&#39; Plot raw data when `d = 1` #&#39; &lt;&lt;y-param&gt;&gt; #&#39; #&#39; @export plot_data &lt;- function(y) { stopifnot(ncol(y[[1]]) == 1) purrr::map_dfr(y, ~ tibble::tibble(y = .x), .id = &quot;time&quot;) %&gt;% dplyr::mutate(time = as.numeric(.data$time)) %&gt;% ggplot2::ggplot(ggplot2::aes(x = .data$time, y = .data$y)) + ggplot2::geom_point(alpha = 0.2) } We’ve used some functions from other packages, so let’s include those in our package: usethis::use_pipe() usethis::use_package(&quot;purrr&quot;) usethis::use_package(&quot;tibble&quot;) usethis::use_package(&quot;dplyr&quot;) usethis::use_package(&quot;ggplot2&quot;) usethis::use_import_from(&quot;rlang&quot;, &quot;.data&quot;) ## ✔ Adding &#39;magrittr&#39; to Imports field in DESCRIPTION ## ✔ Writing &#39;R/utils-pipe.R&#39; ## • Run `devtools::document()` to update &#39;NAMESPACE&#39; ## ✔ Adding &#39;purrr&#39; to Imports field in DESCRIPTION ## • Refer to functions with `purrr::fun()` ## ✔ Adding &#39;tibble&#39; to Imports field in DESCRIPTION ## • Refer to functions with `tibble::fun()` ## ✔ Adding &#39;dplyr&#39; to Imports field in DESCRIPTION ## • Refer to functions with `dplyr::fun()` ## ✔ Adding &#39;ggplot2&#39; to Imports field in DESCRIPTION ## • Refer to functions with `ggplot2::fun()` ## ✔ Adding &#39;rlang&#39; to Imports field in DESCRIPTION ## ✔ Adding &#39;@importFrom rlang .data&#39; to &#39;R/flowkernel-package.R&#39; ## ✔ Writing &#39;NAMESPACE&#39; Let’s look at our example data using this plotting function: plot_data(ex1$dat$y) 2.3 Visualizing data and model in one-dimensional case We’ll also want a function for plotting the data with points colored by true (or estimated) cluster. And it will be convenient to also be able to superimpose the true (or estimated) means. The next function does this: #&#39; Plot data colored by cluster assignment with cluster means when `d=1` #&#39; &lt;&lt;y-param&gt;&gt; #&#39; @param z a length T list with `z[[t]]` being a n_t vector of cluster assignments #&#39; @param mu a T-by-K-by-d array of means plot_data_and_model &lt;- function(y, z, mu) { dat_df &lt;- purrr::map2_dfr(z, y, ~ tibble::tibble(z = as.factor(.x), y = .y), .id = &quot;time&quot;) %&gt;% dplyr::mutate(time = as.numeric(.data$time)) means_df &lt;- tibble::as_tibble(mu[, , 1]) %&gt;% dplyr::mutate(time = dplyr::row_number()) %&gt;% tidyr::pivot_longer(-.data$time, names_to = &quot;cluster&quot;, values_to = &quot;mean&quot;) ggplot2::ggplot() + ggplot2::geom_point( data = dat_df, ggplot2::aes(x = .data$time, y = .data$y, color = .data$z), alpha = 0.2 ) + ggplot2::geom_line( data = means_df, ggplot2::aes(x = .data$time, y = .data$mean, group = .data$cluster) ) } We used a function from tidyr, so let’s include this package: usethis::use_package(&quot;tidyr&quot;) ## ✔ Adding &#39;tidyr&#39; to Imports field in DESCRIPTION ## • Refer to functions with `tidyr::fun()` For now we can use this to visualize the true model, although later this will be useful for visualizing the estimated model. plot_data_and_model(ex1$dat$y, ex1$dat$z, ex1$dat$mu) "],["the-method.html", "3 The method 3.1 Initialization 3.2 E-step 3.3 M-step 3.4 Trying out the method", " 3 The method Given a kernel \\(w_h(t)\\) with bandwidth \\(h\\), consider the following EM-inspired algorithm. Here’s a high-level look at the algorithm. We’ll discuss the initialization, E-step, and M-step in the next subsections. #&#39; Kernel-smoothed EM algorithm #&#39; &lt;&lt;y-param&gt;&gt; #&#39; @param K number of components #&#39; @param hmu bandwidth for mu parameter #&#39; @param hSigma bandwidth for Sigma parameter #&#39; @param hpi bandwidth for pi parameter #&#39; @param num_iter number of iterations of EM to perform #&#39; @export kernel_em &lt;- function(y, K, hmu, hSigma, hpi, num_iter = 100) { num_times &lt;- length(y) d &lt;- ncol(y[[1]]) mu &lt;- array(NA, c(num_times, K, d)) Sigma &lt;- array(NA, c(num_times, K, d, d)) pi &lt;- matrix(NA, num_times, K) resp &lt;- list() # responsibilities gamma[[t]][i, k] &lt;&lt;initialize-with-mclust&gt;&gt; for (l in seq(num_iter)) { &lt;&lt;E-step&gt;&gt; &lt;&lt;M-step&gt;&gt; } dimnames(mu) &lt;- list(NULL, paste0(&quot;cluster&quot;, 1:K), NULL) dimnames(Sigma) &lt;- list(NULL, paste0(&quot;cluster&quot;, 1:K), NULL, NULL) dimnames(pi) &lt;- list(NULL, paste0(&quot;cluster&quot;, 1:K)) list(mu = mu, Sigma = Sigma, pi = pi, resp = resp) } 3.1 Initialization To initialize \\((\\mu_t,\\Sigma_t,\\pi_t)\\) for \\(t=1,\\ldots, T\\), we fit a separate Gaussian mixture model for each \\(t\\). We use mclust to do this. ###&quot;initialize-with-mclust&quot;### # use mclust to get initial mu, Sigma, pi for each time t: if (d &gt; 1) stop(&quot;not yet implemented. Should call VVV rather than V&quot;) for (tt in seq(num_times)) { fit &lt;- mclust::Mclust(y[[tt]], G = K, modelNames = &quot;V&quot;) mu[tt, , 1] &lt;- fit$parameters$mean Sigma[tt, , 1, 1] &lt;- fit$parameters$variance$sigmasq pi[tt, ] &lt;- fit$parameters$pro } usethis::use_package(&quot;mclust&quot;) ## ✔ Adding &#39;mclust&#39; to Imports field in DESCRIPTION ## • Refer to functions with `mclust::fun()` Let’s have a look at what the initialization does on our example data. library(mclust) num_times &lt;- length(ex1$dat$y) y &lt;- ex1$dat$y mu &lt;- ex1$dat$mu Sigma &lt;- ex1$dat$Sigma pi &lt;- ex1$dat$pi &lt;&lt;initialize-with-mclust&gt;&gt; plot_data_and_model(y,ex1$dat$z, mu) ## Package &#39;mclust&#39; version 6.0.0 ## Type &#39;citation(&quot;mclust&quot;)&#39; for citing this R package in publications. The means are jagged because we have not used any smoothness information yet. 3.2 E-step Given an estimate of \\((\\mu,\\Sigma,\\pi)\\), the E-step computes for each \\(Y_{it}\\) how “responsible” each cluster is for it. In particular, the responsibility vector \\((\\hat\\gamma_{it1},\\ldots,\\hat\\gamma_{itK})\\) is a probability vector. It is computed using Bayes rule: \\[ \\hat\\gamma_{itk}=\\hat{\\mathbb{P}}(Z_{it}=k|Y_{it})=\\frac{\\hat \\pi_{tk}\\phi(Y_{it};\\hat\\mu_{tk},\\hat\\Sigma_{tk})}{\\sum_{\\ell=1}^K\\hat \\pi_{t\\ell}\\phi(Y_{it};\\hat\\mu_{t\\ell },\\hat\\Sigma_{t\\ell})} \\] ###&quot;E-step&quot;### # E-step: update responsibilities if (d &gt; 1) stop(&quot;not yet implemented. Should use mvtnorm::dmvtnorm()&quot;) for (tt in seq(num_times)) { phi &lt;- matrix(NA, nrow(y[[tt]]), K) for (k in seq(K)) { phi[, k] &lt;- stats::dnorm(y[[tt]], mean = mu[tt, k, 1], sd = sqrt(Sigma[tt, k, 1, 1])) } temp &lt;- t(t(phi) * pi[tt, ]) resp[[tt]] &lt;- temp / rowSums(temp) } Let’s have a look at the responsibilities that we get using the initial parameter estimates: resp &lt;- list() # responsibilities gamma[[t]][i, k] &lt;&lt;E-step&gt;&gt; Here are some from the 50th time point: resp[[50]][1:4, ] ## [,1] [,2] ## [1,] 1.000000e+00 7.040453e-18 ## [2,] 4.061480e-22 1.000000e+00 ## [3,] 3.281805e-28 1.000000e+00 ## [4,] 1.050034e-29 1.000000e+00 zest &lt;- resp %&gt;% purrr::map(~ max.col(.x)) plot_data_and_model(y, zest, mu = mu) Looks reasonable! Notice that there are a small number of obviously incorrectly labeled points. My guess is this has to do with situations in which the labels of the clusters from mclust are swapped. Without anything tying together the separate clusterings at each time, there is no reason why cluster 1 and cluster 2 should have the same meaning across different times. However, after the M-step imposes smoothness, I believe this should straighten out these stray points. 3.3 M-step In the M-step, we update the estimates of \\((\\mu,\\Sigma,\\pi)\\): ###&quot;M-step&quot;### # M-step: update estimates of (mu, Sigma, pi) &lt;&lt;M-step-pi&gt;&gt; &lt;&lt;M-step-mu&gt;&gt; &lt;&lt;M-step-Sigma&gt;&gt; Define \\[ \\hat\\gamma_{\\cdot sk}=\\sum_{i=1}^{n_s}\\hat\\gamma_{isk}, \\] which is an estimate of the number of points in class \\(k\\) at time \\(s\\), and define \\[ \\tilde\\gamma_{\\cdot sk}=\\sum_{s=1}^Tw_h(t-s)\\hat\\gamma_{\\cdot sk}, \\] which is a smoothed version of this estimate. Then we estimate \\(\\pi\\) as follows: \\[ \\hat\\pi_{tk}=\\frac{\\sum_{s=1}^Tw_h(t-s)\\hat\\gamma_{\\cdot sk}}{\\sum_{s=1}^T{w_h(t-s)n_s}}=\\frac{\\tilde\\gamma_{\\cdot tk}}{\\sum_{s=1}^T{w_h(t-s)n_s}} \\] For \\(\\mu\\): \\[ \\hat\\mu_{tk}=\\frac{\\sum_{s=1}^Tw_h(t-s)\\sum_{i=1}^{n_s}\\hat\\gamma_{isk}Y_{is}}{\\tilde\\gamma_{\\cdot tk}} \\] For \\(\\Sigma\\): \\[ \\hat\\Sigma_{tk}=\\frac{\\sum_{s=1}^Tw_h(t-s)\\sum_{i=1}^{n_s}\\hat\\gamma_{isk}(Y_{is}-\\hat\\mu_{sk})(Y_{is}-\\hat\\mu_{sk})^\\top}{\\tilde\\gamma_{\\cdot tk}} \\] Each of these quantities involves a summation over \\(i\\) before the smoothing over time. In each case we do the summation over \\(i\\) first so that then all quantities can be expressed as an array (rather than as lists). This should make the smoothing more efficient. 3.3.1 M-step \\(\\pi\\) For \\(\\pi\\) estimation, we compute \\[ \\hat\\gamma_{\\cdot sk}=\\sum_{i=1}^{n_s}\\hat\\gamma_{isk}, \\] And then we compute the kernel smoothed version of this: \\[ \\tilde\\gamma_{\\cdot sk}=\\sum_{s=1}^Tw_h(t-s)\\hat\\gamma_{\\cdot sk}, \\] We are then ready to compute the following: \\[ \\hat\\pi_{tk}=\\frac{\\sum_{s=1}^Tw_h(t-s)\\hat\\gamma_{\\cdot sk}}{\\sum_{s=1}^T{w_h(t-s)n_s}}=\\frac{\\tilde\\gamma_{\\cdot tk}}{\\sum_{s=1}^T{w_h(t-s)n_s}} \\] ###&quot;M-step-pi&quot;### # do summations over i: # form T-by-K matrix summing resp_itk over i resp_sum &lt;- purrr::map(resp, ~ colSums(.x)) %&gt;% unlist() %&gt;% matrix(ncol = 2, byrow = TRUE) resp_sum_smooth &lt;- apply( resp_sum, 2, function(x) stats::ksmooth(1:length(x), x, bandwidth = hpi)$y ) pi &lt;- resp_sum_smooth / rowSums(resp_sum_smooth) Here was an example that I used to figure out how to use the ksmooth() function: xx &lt;- 5 * sin((1:100) / 5) + rnorm(100) plot(xx, type=&quot;o&quot;) lines(stats::ksmooth(1:length(xx), xx, bandwidth = 5), col=&quot;red&quot;) lines(stats::ksmooth(1:length(xx), xx, bandwidth = 20), col=&quot;blue&quot;) 3.3.2 M-step \\(\\mu\\) Next, we compute the estimate of \\(\\mu\\). We again first compute the unsmoothed estimate and then apply smoothing to it: \\[ \\sum_{i=1}^{n_s}\\hat\\gamma_{isk}Y_{is} \\] This is then used in the following smoothed estimate: \\[ \\hat\\mu_{tk}=\\frac{\\sum_{s=1}^Tw_h(t-s)\\sum_{i=1}^{n_s}\\hat\\gamma_{isk}Y_{is}}{\\tilde\\gamma_{\\cdot tk}} \\] ###&quot;M-step-mu&quot;### # form T-by-K-by-d array summing resp_itk * Y_ij over i y_sum &lt;- purrr::map2(resp, y, ~ crossprod(.x, .y)) %&gt;% unlist() %&gt;% array(c(K, d, num_times)) %&gt;% aperm(c(3,1,2)) y_sum_smoothed &lt;- apply( y_sum, 2:3, function(x) stats::ksmooth(1:length(x), x, bandwidth = hmu)$y ) for (j in seq(d)) { mu[, , j] &lt;- y_sum_smoothed[, , j] / resp_sum_smooth } In the above code for y_sum, I convert a list of length \\(T\\), where each list element is a \\(K\\times d\\) matrix, to a \\(T\\times K\\times d\\) array. To verify that this conversion is done correctly, I tried this small example: a &lt;- list(matrix(1:12, 4, 3), matrix(13:24, 4, 3)) a a %&gt;% unlist() %&gt;% array(c(4,3,2)) ## [[1]] ## [,1] [,2] [,3] ## [1,] 1 5 9 ## [2,] 2 6 10 ## [3,] 3 7 11 ## [4,] 4 8 12 ## ## [[2]] ## [,1] [,2] [,3] ## [1,] 13 17 21 ## [2,] 14 18 22 ## [3,] 15 19 23 ## [4,] 16 20 24 ## , , 1 ## ## [,1] [,2] [,3] ## [1,] 1 5 9 ## [2,] 2 6 10 ## [3,] 3 7 11 ## [4,] 4 8 12 ## ## , , 2 ## ## [,1] [,2] [,3] ## [1,] 13 17 21 ## [2,] 14 18 22 ## [3,] 15 19 23 ## [4,] 16 20 24 3.3.3 M-step \\(\\Sigma\\) We start by computing \\[ \\sum_{i=1}^{n_s}\\hat\\gamma_{isk}(Y_{is}-\\hat\\mu_{sk})(Y_{is}-\\hat\\mu_{sk})^\\top \\] and then go on to compute \\[ \\hat\\Sigma_{tk}=\\frac{\\sum_{s=1}^Tw_h(t-s)\\sum_{i=1}^{n_s}\\hat\\gamma_{isk}(Y_{is}-\\hat\\mu_{sk})(Y_{is}-\\hat\\mu_{sk})^\\top}{\\tilde\\gamma_{\\cdot tk}} \\] ###&quot;M-step-Sigma&quot;### # form a T-by-K-by-d-by-d array # summing (Y_it - mu_t)*diag(resp_itk)*(Y_it - mu_t)^T over i mat_sum &lt;- array(NA, c(num_times, K, d, d)) for (tt in seq(num_times)) { for (k in seq(K)) { yy &lt;- y[[tt]] - mu[tt, k, ] mat_sum[tt, k, , ] &lt;- crossprod(yy, yy * resp[[tt]][, k]) # YY^T * D * YY } } mat_sum_smoothed &lt;- apply( mat_sum, 2:4, function(x) stats::ksmooth(1:length(x), x, bandwidth = hSigma)$y ) for (j in seq(d)) for (l in seq(d)) Sigma[, , j, l] &lt;- mat_sum_smoothed[, , j, l] / resp_sum_smooth 3.4 Trying out the method fit &lt;- kernel_em(ex1$dat$y, K = 2, hmu = 5, hSigma = 5, hpi = 5, num_iter = 20) zest &lt;- fit$resp %&gt;% purrr::map(~ max.col(.x)) plot_data_and_model(ex1$dat$y, zest, fit$mu) fit &lt;- kernel_em(ex1$dat$y, K = 2, hmu = 50, hSigma = 50, hpi = 50, num_iter = 10) zest &lt;- fit$resp %&gt;% purrr::map(~ max.col(.x)) plot_data_and_model(ex1$dat$y, zest, fit$mu) "],["conclude.html", "4 Conclusion", " 4 Conclusion When you are done defining the package, it remains to convert the Roxygen to documentation. litr::document() # &lt;-- use instead of devtools::document() ## ℹ Updating flowkernel documentation ## ℹ Loading flowkernel ## Writing &#39;]8;;file:///Users/jacobbien/Documents/GitHub/flowkernel-project/flowkernel/NAMESPACENAMESPACE]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;flowkernel-package&#39;)flowkernel-package.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;generate_smooth_gauss_mix&#39;)generate_smooth_gauss_mix.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;kernel_em&#39;)kernel_em.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;plot_data&#39;)plot_data.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;plot_data_and_model&#39;)plot_data_and_model.Rd]8;;&#39; ## Writing &#39;]8;;ide:run:pkgload::dev_help(&#39;%&gt;%&#39;)pipe.Rd]8;;&#39; You can also add some extra things to your package here if you like, such as a README, some vignettes, a pkgdown site, etc. See here for an example of how to do this with litr. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
